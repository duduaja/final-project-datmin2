{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3fce35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ab7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_folder(path):\n",
    "    lst = []\n",
    "    for img in glob.glob(path+'*.jpg'):\n",
    "        n= plt.imread(img)\n",
    "        lst.append(n)\n",
    "    return np.array(lst)\n",
    "\n",
    "# awake_img = np.array(awake_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecd9add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "awake_path = \"C:/Users/ACER/OneDrive - Universitas Airlangga/KULIAH/semester 5/bbb data mining/final_project/final-project-datmin2/images/awake/awake\"\n",
    "drowsy_path = \"C:/Users/ACER/OneDrive - Universitas Airlangga/KULIAH/semester 5/bbb data mining/final_project/final-project-datmin2/images/drowsy/drowsy\"\n",
    "# awake_path = \"/images/awake/awake\"\n",
    "# drowsy_path = \"/images/drowsy/drowsy\"\n",
    "awake_img = load_img_folder(awake_path)\n",
    "drowsy_img = load_img_folder(drowsy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "719bef89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 480, 640, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awake_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "578790a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 480, 640, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drowsy_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96ab4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_facemesh = mp.solutions.face_mesh\n",
    "mp_drawing  = mp.solutions.drawing_utils\n",
    "denormalize_coordinates = mp_drawing._normalized_to_pixel_coordinates\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Landmark points corresponding to left eye\n",
    "all_left_eye_idxs = list(mp_facemesh.FACEMESH_LEFT_EYE)\n",
    "# flatten and remove duplicates\n",
    "all_left_eye_idxs = set(np.ravel(all_left_eye_idxs)) \n",
    "\n",
    "# Landmark points corresponding to right eye\n",
    "all_right_eye_idxs = list(mp_facemesh.FACEMESH_RIGHT_EYE)\n",
    "all_right_eye_idxs = set(np.ravel(all_right_eye_idxs))\n",
    "\n",
    "# Combined for plotting - Landmark points for both eye\n",
    "all_idxs = all_left_eye_idxs.union(all_right_eye_idxs)\n",
    "\n",
    "# The chosen 12 points:   P1,  P2,  P3,  P4,  P5,  P6\n",
    "chosen_left_eye_idxs  = [362, 385, 387, 263, 373, 380]\n",
    "chosen_right_eye_idxs = [33,  160, 158, 133, 153, 144]\n",
    "all_chosen_idxs = chosen_left_eye_idxs + chosen_right_eye_idxs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e07e3823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(point_1, point_2):\n",
    "    \"\"\"Calculate l2-norm between two points\"\"\"\n",
    "    dist = sum([(i - j) ** 2 for i, j in zip(point_1, point_2)]) ** 0.5\n",
    "    return dist\n",
    "\n",
    "def get_ear(landmarks, refer_idxs, frame_width, frame_height):\n",
    "    \"\"\"\n",
    "    Calculate Eye Aspect Ratio for one eye.\n",
    "\n",
    "    Args:\n",
    "        landmarks: (list) Detected landmarks list\n",
    "        refer_idxs: (list) Index positions of the chosen landmarks\n",
    "                            in order P1, P2, P3, P4, P5, P6\n",
    "        frame_width: (int) Width of captured frame\n",
    "        frame_height: (int) Height of captured frame\n",
    "\n",
    "    Returns:\n",
    "        ear: (float) Eye aspect ratio\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Compute the euclidean distance between the horizontal\n",
    "        coords_points = []\n",
    "        for i in refer_idxs:\n",
    "            lm = landmarks[i]\n",
    "            coord = denormalize_coordinates(lm.x, lm.y, \n",
    "                                             frame_width, frame_height)\n",
    "            coords_points.append(coord)\n",
    "\n",
    "        # Eye landmark (x, y)-coordinates\n",
    "        P2_P6 = distance(coords_points[1], coords_points[5])\n",
    "        P3_P5 = distance(coords_points[2], coords_points[4])\n",
    "        P1_P4 = distance(coords_points[0], coords_points[3])\n",
    "\n",
    "        # Compute the eye aspect ratio\n",
    "        ear = (P2_P6 + P3_P5) / (2.0 * P1_P4)\n",
    "\n",
    "    except:\n",
    "        ear = 0.0\n",
    "        coords_points = None\n",
    "\n",
    "    return ear, coords_points\n",
    "\n",
    "def calculate_avg_ear(landmarks, left_eye_idxs, right_eye_idxs, image_w, image_h):\n",
    "    \"\"\"Calculate Eye aspect ratio\"\"\"\n",
    "\n",
    "    left_ear, left_lm_coordinates = get_ear(\n",
    "                                      landmarks, \n",
    "                                      left_eye_idxs, \n",
    "                                      image_w, \n",
    "                                      image_h\n",
    "                                    )\n",
    "    right_ear, right_lm_coordinates = get_ear(\n",
    "                                      landmarks, \n",
    "                                      right_eye_idxs, \n",
    "                                      image_w, \n",
    "                                      image_h\n",
    "                                    )\n",
    "    Avg_EAR = (left_ear + right_ear) / 2.0\n",
    "\n",
    "    return Avg_EAR, (left_lm_coordinates, right_lm_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5f1a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_ear(img_read, ear_thresh=0.2):\n",
    "    image = np.ascontiguousarray(img_read)\n",
    "    imgH, imgW, _ = image.shape\n",
    "    custom_chosen_lmk_image = image.copy()\n",
    "    \n",
    "    with mp_facemesh.FaceMesh(refine_landmarks=True) as face_mesh:\n",
    "        results = face_mesh.process(image).multi_face_landmarks\n",
    "        \n",
    "        if results:\n",
    "            for face_id, face_landmarks in enumerate(results):\n",
    "                landmarks = face_landmarks.landmark\n",
    "                EAR, _ = calculate_avg_ear(\n",
    "                          landmarks, \n",
    "                          chosen_left_eye_idxs, \n",
    "                          chosen_right_eye_idxs, \n",
    "                          imgW, \n",
    "                          imgH\n",
    "                      )\n",
    "                if EAR < ear_thresh:\n",
    "                    return [EAR, 'drowsy']\n",
    "                elif EAR >= ear_thresh:\n",
    "                    return [EAR, 'awake']\n",
    "#                 return EAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c4090ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodness_model(awake_array, drowsy_array, ear_thresh=0.2):\n",
    "    hasil_awake = []\n",
    "    for i in range(len(awake_array)):\n",
    "        try:\n",
    "            ear_result = final_ear(awake_array[i],ear_thresh)[1]\n",
    "            hasil_awake.append(ear_result)    \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    hasil_drowsy = []\n",
    "    for i in range(len(drowsy_array)):\n",
    "        try:\n",
    "            ear_result = final_ear(drowsy_array[i],ear_thresh)[1]\n",
    "            hasil_drowsy.append(ear_result)    \n",
    "        except:\n",
    "            pass \n",
    "        \n",
    "    con_matrix = np.array([[hasil_awake.count('awake'), hasil_awake.count('drowsy')],\n",
    "              [hasil_drowsy.count('awake'), hasil_drowsy.count('drowsy')]])\n",
    "    \n",
    "    TP = con_matrix[0][0]\n",
    "    FN = con_matrix[0][1]\n",
    "    FP = con_matrix[1][0]\n",
    "    TN = con_matrix[1][1]\n",
    "\n",
    "    ear_acc = (TP+TN)/(TP+TN+FN+FP)\n",
    "    ear_rec = (TP)/(TP+FN)\n",
    "    ear_pre = (TP)/(TP+FP)\n",
    "    ear_f1s = (2*TP)/(2*TP+FP+FN)\n",
    "    \n",
    "    result = {'acc': ear_acc,\n",
    "              'rec': ear_rec,\n",
    "              'pre': ear_pre,\n",
    "              'f1s': ear_f1s}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de9fe3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_018 = goodness_model(awake_img, drowsy_img, 0.18)\n",
    "thresh_019 = goodness_model(awake_img, drowsy_img, 0.19)\n",
    "thresh_020 = goodness_model(awake_img, drowsy_img, 0.2)\n",
    "thresh_021 = goodness_model(awake_img, drowsy_img, 0.21)\n",
    "thresh_022 = goodness_model(awake_img, drowsy_img, 0.22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da6770e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_metode = ['thresh_018','thresh_019','thresh_020','thresh_021','thresh_022']\n",
    "list_acc = []\n",
    "list_rec = []\n",
    "list_pre = []\n",
    "list_f1s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36ba72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_thresh = [thresh_018,thresh_019,thresh_020,thresh_021,thresh_022]\n",
    "list_param = ['acc','rec','pre','f1s']\n",
    "\n",
    "for i in list_thresh:\n",
    "    for j in i:\n",
    "        if j=='acc':\n",
    "            list_acc.append(i[j])\n",
    "        elif j=='rec':\n",
    "            list_rec.append(i[j])\n",
    "        elif j=='pre':\n",
    "            list_pre.append(i[j])\n",
    "        elif j=='f1s':\n",
    "            list_f1s.append(i[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc122820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f6f49_row0_col1, #T_f6f49_row1_col1, #T_f6f49_row1_col3, #T_f6f49_row2_col2, #T_f6f49_row2_col4 {\n",
       "  background-color: #ff0000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f6f49_row0_col2 {\n",
       "  background-color: #f79898;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f6f49_row0_col3 {\n",
       "  background-color: #fb5757;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f6f49_row0_col4 {\n",
       "  background-color: #f97c7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f6f49_row1_col2, #T_f6f49_row1_col4, #T_f6f49_row2_col3, #T_f6f49_row4_col1 {\n",
       "  background-color: #f3f0f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f6f49_row2_col1, #T_f6f49_row3_col1 {\n",
       "  background-color: #fb5050;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f6f49_row3_col2 {\n",
       "  background-color: #fe1616;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f6f49_row3_col3 {\n",
       "  background-color: #f4e1e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f6f49_row3_col4 {\n",
       "  background-color: #fe1818;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f6f49_row4_col2 {\n",
       "  background-color: #fb5858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f6f49_row4_col3 {\n",
       "  background-color: #f3e8e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f6f49_row4_col4 {\n",
       "  background-color: #f4dbdb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f6f49\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f6f49_level0_col0\" class=\"col_heading level0 col0\" >metode</th>\n",
       "      <th id=\"T_f6f49_level0_col1\" class=\"col_heading level0 col1\" >akurasi</th>\n",
       "      <th id=\"T_f6f49_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
       "      <th id=\"T_f6f49_level0_col3\" class=\"col_heading level0 col3\" >precision</th>\n",
       "      <th id=\"T_f6f49_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f6f49_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f6f49_row0_col0\" class=\"data row0 col0\" >thresh_021</td>\n",
       "      <td id=\"T_f6f49_row0_col1\" class=\"data row0 col1\" >0.793478</td>\n",
       "      <td id=\"T_f6f49_row0_col2\" class=\"data row0 col2\" >0.912088</td>\n",
       "      <td id=\"T_f6f49_row0_col3\" class=\"data row0 col3\" >0.734513</td>\n",
       "      <td id=\"T_f6f49_row0_col4\" class=\"data row0 col4\" >0.813725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6f49_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f6f49_row1_col0\" class=\"data row1 col0\" >thresh_022</td>\n",
       "      <td id=\"T_f6f49_row1_col1\" class=\"data row1 col1\" >0.793478</td>\n",
       "      <td id=\"T_f6f49_row1_col2\" class=\"data row1 col2\" >0.868132</td>\n",
       "      <td id=\"T_f6f49_row1_col3\" class=\"data row1 col3\" >0.752381</td>\n",
       "      <td id=\"T_f6f49_row1_col4\" class=\"data row1 col4\" >0.806122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6f49_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f6f49_row2_col0\" class=\"data row2 col0\" >thresh_018</td>\n",
       "      <td id=\"T_f6f49_row2_col1\" class=\"data row2 col1\" >0.788043</td>\n",
       "      <td id=\"T_f6f49_row2_col2\" class=\"data row2 col2\" >0.989011</td>\n",
       "      <td id=\"T_f6f49_row2_col3\" class=\"data row2 col3\" >0.703125</td>\n",
       "      <td id=\"T_f6f49_row2_col4\" class=\"data row2 col4\" >0.821918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6f49_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f6f49_row3_col0\" class=\"data row3 col0\" >thresh_019</td>\n",
       "      <td id=\"T_f6f49_row3_col1\" class=\"data row3 col1\" >0.788043</td>\n",
       "      <td id=\"T_f6f49_row3_col2\" class=\"data row3 col2\" >0.978022</td>\n",
       "      <td id=\"T_f6f49_row3_col3\" class=\"data row3 col3\" >0.706349</td>\n",
       "      <td id=\"T_f6f49_row3_col4\" class=\"data row3 col4\" >0.820276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6f49_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f6f49_row4_col0\" class=\"data row4 col0\" >thresh_020</td>\n",
       "      <td id=\"T_f6f49_row4_col1\" class=\"data row4 col1\" >0.777174</td>\n",
       "      <td id=\"T_f6f49_row4_col2\" class=\"data row4 col2\" >0.945055</td>\n",
       "      <td id=\"T_f6f49_row4_col3\" class=\"data row4 col3\" >0.704918</td>\n",
       "      <td id=\"T_f6f49_row4_col4\" class=\"data row4 col4\" >0.807512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22be5d96f10>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "summ = pd.DataFrame({\"metode\":list_metode,\n",
    "                    'akurasi':list_acc,\n",
    "                    'recall':list_rec,\n",
    "                    'precision': list_pre,\n",
    "                    'f1-score': list_f1s})\n",
    "summ = summ.sort_values(by=['akurasi'],ascending=False).reset_index(drop=True)\n",
    "cm = sns.light_palette(\"red\", as_cmap=True)\n",
    "summ.style.background_gradient(cmap=cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
